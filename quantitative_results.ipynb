{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from ternary.helpers import project_sequence\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "from sklearn.manifold import spectral_embedding\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from matplotlib import path\n",
    "import gpflow\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as colors\n",
    "import ternary\n",
    "\n",
    "from applied_active_learning_220608a import GRF_RiskMin_simplified\n",
    "\n",
    "from sklearn.metrics import fowlkes_mallows_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the experimental data, including the...\n",
    "experimental_data = loadmat('FeGaPd_full_data_220104a.mat')\n",
    "\n",
    "# ...\"true\" labels from the data set, ...\n",
    "true_labels = experimental_data['labels_col'][0][1].flatten()\n",
    "\n",
    "# ...composition data in cartesian coordinates, ...\n",
    "composition = experimental_data['C']\n",
    "idx = [1, 2, 0]\n",
    "cartesian = np.array(list(zip(*project_sequence(composition[:, idx]))))\n",
    "\n",
    "# ...and x ray diffraction data\n",
    "xrd = experimental_data['X'][:, 631:1181]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process Classification Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(X, metric, sigma=1):\n",
    "    '''\n",
    "    Calculate and return the similarity matrix used in spectral clustering.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: m x n matrix - m rows of n dimensional data\n",
    "    metric: distance metric passed to scipy.spatial.distance.pdist()\n",
    "    sigma: scaling factor for Gaussian radial basis function (default=1)\n",
    "    '''\n",
    "\n",
    "    distance = squareform(pdist(X, metric))\n",
    "    W = np.exp(-(distance**2) / (2*sigma**2))\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_mapping(X, num_clusters, random_state):\n",
    "    '''\n",
    "    Cluster data using spectral clustering and a Gaussian mixture model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: m x n matrix - m rows of n dimensional data\n",
    "    num_clusters: number of groups to cluster data into\n",
    "    random_state: a numpy RandomState for reproducibility \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cl: clustering labels for each sample\n",
    "    cluster_prob: the probability for each sample to belong to each cluster\n",
    "    '''\n",
    "\n",
    "    K = similarity_matrix(X, 'cosine')\n",
    "\n",
    "    if X.shape[0] <= num_clusters:\n",
    "        # fewer data points than clusters, each point gets its own cluster\n",
    "        cluster_prob = np.eye(X.shape[0])\n",
    "    else:\n",
    "        x_se = spectral_embedding(adjacency=K,\n",
    "                                  n_components=num_clusters,\n",
    "                                  random_state=random_state)\n",
    "        model = GaussianMixture(n_components=num_clusters,\n",
    "                                covariance_type='diag',\n",
    "                                n_init=10,\n",
    "                                random_state=random_state).fit(x_se)\n",
    "\n",
    "        cluster_prob = model.predict_proba(x_se)\n",
    "\n",
    "    cl = np.argmax(cluster_prob, axis=1).flatten()\n",
    "    return cl, cluster_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_labels(points):\n",
    "    '''\n",
    "    Return the user labels created using the provided user input\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    points: a list of tuples of the user input cartesian coordinates\n",
    "    '''\n",
    "\n",
    "    if len(points) < 2:\n",
    "        raise ValueError('User didn\\'t add enough points.')\n",
    "    elif len(points) == 2:\n",
    "        # user drew a line\n",
    "        x1, y1 = points[0]\n",
    "        x2, y2 = points[1]\n",
    "\n",
    "        # calculate the distance between each point the line\n",
    "        d = [(x-x1)*(y2-y1)-(y-y1)*(x2-x1) for (x, y) in cartesian]\n",
    "\n",
    "        user_labels = [1 if distance > 0 else 0 for distance in d]\n",
    "    else:\n",
    "        # user draw a polygon\n",
    "        polygon = path.Path(points)\n",
    "\n",
    "        user_labels = polygon.contains_points(cartesian)\n",
    "    \n",
    "    return(np.array(user_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_mapping_with_input(X, num_clusters, random_state, points, measured):\n",
    "    '''\n",
    "    Cluster data using spectral clustering and a Gaussian mixture model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: m x n matrix - m rows of n dimensional data\n",
    "    num_clusters: number of groups to cluster data into\n",
    "    random_state: a numpy RandomState for reproducibility\n",
    "    points: a list of tuples of the user input cartesian coordinates\n",
    "    measured: list of samples which have been measured\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cl: clustering labels for each sample\n",
    "    cluster_prob: the probability for each sample to belong to each cluster\n",
    "    '''\n",
    "\n",
    "    K = similarity_matrix(X, 'cosine')\n",
    "\n",
    "    user_labels = np.expand_dims(get_user_labels(points)[measured], 1)\n",
    "\n",
    "    # if len(points) == 2:\n",
    "    if True:\n",
    "        user_kernel = gpflow.kernels.SquaredExponential(lengthscales=0.001)\n",
    "    else:\n",
    "        user_kernel = gpflow.kernels.Linear()\n",
    "\n",
    "    K += user_kernel.K(user_labels).numpy()\n",
    "\n",
    "    if X.shape[0] <= num_clusters:\n",
    "        # fewer data points than clusters, each point gets its own cluster\n",
    "        cluster_prob = np.eye(X.shape[0])\n",
    "    else:\n",
    "        x_se = spectral_embedding(adjacency=K,\n",
    "                                  n_components=num_clusters,\n",
    "                                  random_state=random_state)\n",
    "        model = GaussianMixture(n_components=num_clusters,\n",
    "                                covariance_type='diag',\n",
    "                                n_init=10,\n",
    "                                random_state=random_state).fit(x_se)\n",
    "\n",
    "        cluster_prob = model.predict_proba(x_se)\n",
    "\n",
    "    cl = np.argmax(cluster_prob, axis=1).flatten()\n",
    "    return cl, cluster_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpc_phasemapping(xy_curr, labels_curr, xy_full, num_clusters, \n",
    "                     weight_prior=None, points=None):\n",
    "    '''\n",
    "    Take clustering labels for the samples and then extrapolate them throughout\n",
    "    composition space, segmenting the XY space into 'phase regions'.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xy_curr: cartesian coordinates of measured data points\n",
    "    labels_curr: cluster labels for those data\n",
    "    xy_full: cartesian coordinates of measured and new, query data points\n",
    "    num_clusters: the number of clusters we're assuming exist\n",
    "    weight_prior: variance coefficient factor of (optional) prior kernel\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y_mean: data point label predictions\n",
    "    y_variance: data point label variances\n",
    "    f_mean: data point latent GP predictions\n",
    "    f_variance: data point latent GP variances\n",
    "    points: a list of tuples of the user input cartesian coordinates\n",
    "    '''\n",
    "\n",
    "    data = (xy_curr, labels_curr)\n",
    "\n",
    "    composition_kernel = gpflow.kernels.Matern32(active_dims=[0, 1],\n",
    "                                                 lengthscales=[0.2, 0.2],\n",
    "                                                 variance=1)\n",
    "\n",
    "    gpflow.utilities.set_trainable(composition_kernel.lengthscales, False)\n",
    "    gpflow.utilities.set_trainable(composition_kernel.variance, False)\n",
    "\n",
    "    if weight_prior is None:\n",
    "        kernel = composition_kernel\n",
    "    else:\n",
    "        if len(points) == 2:\n",
    "            # user input was a boundary\n",
    "            prior_kernel = gpflow.kernels.SquaredExponential(\n",
    "                active_dims=[2],\n",
    "                lengthscales=0.001,\n",
    "                variance=weight_prior)\n",
    "\n",
    "            # fix all the kernel hyperparameters\n",
    "            gpflow.utilities.set_trainable(prior_kernel.lengthscales, False)\n",
    "            gpflow.utilities.set_trainable(prior_kernel.variance, False)\n",
    "        else:\n",
    "            # user input was a region\n",
    "            prior_kernel = gpflow.kernels.Linear(active_dims=[2],\n",
    "                                                 variance=weight_prior)\n",
    "\n",
    "            gpflow.utilities.set_trainable(prior_kernel.variance, False)\n",
    "\n",
    "        kernel = composition_kernel + prior_kernel\n",
    "\n",
    "    invlink = gpflow.likelihoods.RobustMax(num_clusters)\n",
    "\n",
    "    gpflow.utilities.set_trainable(invlink.epsilon, True)\n",
    "\n",
    "    likelihood = gpflow.likelihoods.MultiClass(num_clusters, invlink=invlink)\n",
    "\n",
    "    model = gpflow.models.VGP(data=data,\n",
    "                              kernel=kernel,\n",
    "                              likelihood=likelihood,\n",
    "                              num_latent_gps=num_clusters)\n",
    "\n",
    "    # hyperparameter optimization\n",
    "    opt = gpflow.optimizers.Scipy()\n",
    "    opt_result = opt.minimize(model.training_loss,\n",
    "                              model.trainable_variables,\n",
    "                              options={'maxiter': 1000})\n",
    "\n",
    "    # Poisson process for the full XY coordinates\n",
    "    y = model.predict_y(xy_full)\n",
    "    y_mean = y[0].numpy()\n",
    "    y_variance = y[1].numpy()\n",
    "\n",
    "    # (non-squeezed) probabilistic function for class labels\n",
    "    f = model.predict_f(xy_full)\n",
    "    f_mean = f[0].numpy()\n",
    "    f_variance = f[1].numpy()\n",
    "\n",
    "    return y_mean, y_variance, f_mean, f_variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hitl_labels(user_points, measured_indices):\n",
    "    '''\n",
    "    Return the 5th iteration clustering results using the provided user input\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    user_points: a list of tuples of the user input cartesian coordinates\n",
    "    measured_indices: a list of indices of the measured compositions\n",
    "    '''\n",
    "\n",
    "    user_labels = get_user_labels(user_points)\n",
    "\n",
    "    if len(user_points) < 2:\n",
    "        raise ValueError('User didn\\'t add enough points.')\n",
    "    elif len(user_points) == 2:\n",
    "        # user drew a line\n",
    "        x1, y1 = user_points[0]\n",
    "        x2, y2 = user_points[1]\n",
    "\n",
    "        # calculate the distance between each point the line\n",
    "        d = [(x-x1)*(y2-y1)-(y-y1)*(x2-x1) for (x, y) in cartesian]\n",
    "\n",
    "        user_labels = [1 if distance > 0 else 0 for distance in d]\n",
    "    else:\n",
    "        # user draw a polygon\n",
    "        polygon = path.Path(user_points)\n",
    "\n",
    "        user_labels = polygon.contains_points(cartesian)\n",
    "    \n",
    "    labels = [0, 1, 2, 3, 4]\n",
    "\n",
    "    # use the user labels as input\n",
    "    data_with_prior = np.column_stack((cartesian, user_labels))\n",
    "\n",
    "    y_mean, _, _, _ = gpc_phasemapping(data_with_prior[measured_indices, :],\n",
    "                                       labels,\n",
    "                                       data_with_prior,\n",
    "                                       5,\n",
    "                                       weight_prior=1,\n",
    "                                       points=user_points)\n",
    "\n",
    "    return(y_mean)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_points = [(0.2, 0.3), (0.4, 0.3)]\n",
    "# user_points = [(0.07, 0.05), (0.16, 0.25), (0.3, 0.25), (0.1, 0.03)]\n",
    "\n",
    "num_samples = 100\n",
    "num_compositions = composition.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize result arrays\n",
    "measured_indices = np.zeros((num_samples, 5), np.int16)\n",
    "\n",
    "control_labels = np.zeros((num_samples, num_compositions))\n",
    "control_acquisition = np.zeros((num_samples, num_compositions))\n",
    "\n",
    "hitl_labels = np.zeros((num_samples, num_compositions))\n",
    "hitl_acquisition = np.zeros((num_samples, num_compositions))\n",
    "\n",
    "# perform random experiments\n",
    "for i in range(num_samples):\n",
    "    # generate random measurements\n",
    "    measured_indices[i, :] = np.random.choice(a=num_compositions, \n",
    "                                              size=(1, 5),\n",
    "                                              replace=False)\n",
    "\n",
    "    # compute control prediction and acquisition function values \n",
    "    y_mean, _, _, _ = gpc_phasemapping(cartesian[measured_indices[i, :], :],\n",
    "                                       [0, 1, 2, 3, 4],\n",
    "                                       cartesian,\n",
    "                                       5)\n",
    "    control_labels[i, :] = np.argmax(y_mean, 1)\n",
    "\n",
    "    _, risks = GRF_RiskMin_simplified(cartesian, y_mean, measured_indices[i, :])\n",
    "    control_acquisition[i, :] = risks\n",
    "\n",
    "    # compute the hitl prediction and acquisition function values\n",
    "    input_y_mean = get_hitl_labels(user_points, measured_indices[i, :])\n",
    "    hitl_labels[i, :] = np.argmax(input_y_mean, 1)\n",
    "\n",
    "    _, input_risks = GRF_RiskMin_simplified(cartesian,\n",
    "                                                input_y_mean,\n",
    "                                                measured_indices[i, :])\n",
    "    hitl_acquisition[i, :] = input_risks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'boundary'\n",
    "\n",
    "np.savetxt(fname='quantitative_results/' + prefix + '_measured_indices.txt',\n",
    "           X=measured_indices,\n",
    "           fmt='%d')\n",
    "np.savetxt(fname='quantitative_results/' + prefix + '_control_acquisition.txt',\n",
    "           X=control_acquisition,\n",
    "           fmt='%f')\n",
    "np.savetxt(fname='quantitative_results/' + prefix + '_control_labels.txt',\n",
    "           X=control_labels,\n",
    "           fmt='%f')\n",
    "np.savetxt(fname='quantitative_results/' + prefix + '_hitl_acquisition.txt',\n",
    "           X=hitl_acquisition,\n",
    "           fmt='%f')\n",
    "np.savetxt(fname='quantitative_results/' + prefix + '_hitl_labels.txt',\n",
    "           X=hitl_labels,\n",
    "           fmt='%f')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samples From File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_points = [(0.07, 0.05), (0.16, 0.25), (0.3, 0.25), (0.1, 0.03)]\n",
    "\n",
    "# initialize result arrays\n",
    "folder = './quantitative_results/'\n",
    "measured_indices = np.loadtxt(folder + 'boundary_measured_indices.txt',\n",
    "                              dtype=np.int16)\n",
    "\n",
    "control_acquisition = np.zeros((num_samples, num_compositions))\n",
    "\n",
    "hitl_labels = np.zeros((num_samples, num_compositions))\n",
    "hitl_acquisition = np.zeros((num_samples, num_compositions))\n",
    "\n",
    "# perform random experiments\n",
    "for i in range(num_samples):\n",
    "    # compute the hitl prediction and acquisition function values\n",
    "    input_y_mean = get_hitl_labels(user_points, measured_indices[i, :])\n",
    "    hitl_labels[i, :] = np.argmax(input_y_mean, 1)\n",
    "\n",
    "    _, input_risks = GRF_RiskMin_simplified(cartesian,\n",
    "                                                input_y_mean,\n",
    "                                                measured_indices[i, :])\n",
    "    hitl_acquisition[i, :] = input_risks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Results (Again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'region'\n",
    "np.savetxt(fname='quantitative_results/' + prefix + '_hitl_acquisition_2.txt',\n",
    "           X=hitl_acquisition,\n",
    "           fmt='%f')\n",
    "np.savetxt(fname='quantitative_results/' + prefix + '_hitl_labels_2.txt',\n",
    "           X=hitl_labels,\n",
    "           fmt='%f')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute FMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get \"true\" labels\n",
    "true_labels = experimental_data['labels_col'][0][1].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_scores = np.zeros(num_samples)\n",
    "hitl_scores = np.zeros(num_samples)\n",
    "\n",
    "for i in range(num_samples):\n",
    "    control_scores[i] = fowlkes_mallows_score(true_labels, control_labels[i])\n",
    "    hitl_scores[i] = fowlkes_mallows_score(true_labels, hitl_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.hist([control_scores, hitl_scores], label=['control', prefix])\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(fname='quantitative_results/' + prefix + '_control_scores.txt',\n",
    "#            X=control_scores,\n",
    "#            fmt='%f')\n",
    "np.savetxt(fname='quantitative_results/' + prefix + '_hitl_scores_2.txt',\n",
    "           X=hitl_scores,\n",
    "           fmt='%f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hitl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d782e3369a9c649e580e37cdd6febd5b59d5ba3ca94b62266a945741e1c35eee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
